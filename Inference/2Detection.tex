\chapter{Detection Theory}
\label{chapter:Detection}

In this chapter, we study hypothesis testing.
A statistical inference problem is termed detection if the attribute set is partitioned into a finite number of subsets and the objective is to identify which of these subsets $\theta$ belongs to.
We refer to the different subsets as hypotheses, and label them as $H_1, H_2, \ldots$
The design problem consists of finding a decision map that takes observation $Y$ as input, and selects one of the possible hypotheses $\{ H_1, \ldots, H_M \}$ as its output.
That is, a detector is a function from observation space $\Gamma$ to the finite set $\{ H_1, \ldots, H_M \}$.

\begin{center}
\includegraphics[width=5in]{Figures/2Chapter/HypothesisTesting}
\end{center}

The subset of $U$ that contains parameter $\theta$ is called the \emph{true hypothesis}, which we represent by $H$.
The hypothesis $\hat{H}$ that is selected by observing $Y$ is called the \emph{admitted hypothesis}.
For a specific realization of $Y$, a successful detection occurs whenever $\hat{H}(y) = H$; otherwise, the detector is in error and $\hat{H}(y) \neq H$.


\section{Binary Detection}

In its simplest form, the attribute set contains only two elements.
The goal of the detector is to distinguish between the corresponding two hypotheses.
This scenario is called binary detection.

\begin{center}
\includegraphics[width=5in]{Figures/2Chapter/BinaryDetection}
\end{center}


\section{Bayesian Hypothesis Testing}

We first explore binary hypothesis testing in the Bayesian framework.
The attribute set is assumed to be a probability space with a known distribution.
Specifically, we assume that the true parameter $\theta$ is equal to 0 with probability $\nu(0)$, and it is equal to 1 with probability $\nu(1) = 1 - \nu(0)$.
The probability measure on the elements of $U$ is called the \emph{a priori distribution}, and it represents the knowledge we have about the parameter before getting empirical measurements.

One of the possible performance criteria in the Bayes formulation is to find a detector that minimizes the probability of error.
First consider a deterministic detector of the form $\hat{H}: \Gamma \rightarrow \{ 0, 1 \}$.
Then, the probability of error can be computed as
\begin{equation} \label{equation:ErrorProbabilityDetection}
\begin{split}
P_e &=  \Pr \left( \hat{H}(Y) \neq \theta \right) \\
&= \Pr (\theta = 0 ) \Pr \left( \hat{H}(Y) \neq 0 | \theta = 0 \right)
+ \Pr (\theta = 0 ) \Pr \left( \hat{H}(Y) \neq 1 | \theta = 1 \right) \\
&=  \nu(0) \int_{ \Gamma } \SetIn_{ \Gamma_1 } d\mu_0
+ \nu(1) \int_{ \Gamma } \SetIn_{ \Gamma_0 } d\mu_1 .
\end{split}
\end{equation}
where we use the fact that the binary detector $\hat{H}$ partitions the observation space into two subsets
\begin{align*}
\Gamma_0 &= \left\{ y \in \Gamma : \hat{H} (y) = 0 \right\} \\
\Gamma_1 &= \left\{ y \in \Gamma : \hat{H} (y) = 1 \right\}.
\end{align*}
Using this notation, the probability of error can be written in a succinct manner,
\begin{equation*}
P_e = \nu (0) \int_{\Gamma_1} d\mu_0 + \nu (1) \int_{\Gamma_0} d\mu_1 .
\end{equation*}

\begin{example} \label{example:BinaryCommunicationSystemII}
Recall the digital communication system of Example~\ref{example:BinaryCommunicationSystem}.
The source sends a single bit of information over a channel corrupted by additive Gaussian noise.
For a specific detector $\hat{H}$, the probability of error becomes
\begin{equation*}
P_e
=  \nu(0) \int_{-\infty}^{\infty} \SetIn_{ \Gamma_1 }
\frac{1}{\sqrt{2 \pi}} e^{- \frac{y^2}{2}} dy
+ \nu(1) \int_{-\infty}^{\infty} \SetIn_{ \Gamma_0 }
\frac{1}{\sqrt{2 \pi}} e^{- \frac{(y-1)^2}{2}} dy .
\end{equation*}
Further suppose that the detector $\hat{H}$ is a threshold rule on the observed data with threshold $\eta$.
Then, the probability of error simplifies to
\begin{equation*}
\begin{split}
P_e
&=  \nu(0) \int_{-\infty}^{\eta} \frac{1}{\sqrt{2 \pi}} e^{- \frac{y^2}{2}} dy
+ \nu(1) \int_{\eta}^{\infty} \frac{1}{\sqrt{2 \pi}} e^{- \frac{(y-1)^2}{2}} dy \\
&= \nu(0) Q (-\eta) + \nu(1) Q (\eta - 1),
\end{split}
\end{equation*}
where $Q(\cdot)$ is the complementary Gaussian cumulative distribution function
\begin{equation}
Q (\eta) = \int_{\eta}^{\infty} \frac{1}{\sqrt{2 \pi}}
e^{- \frac{\xi^2}{2}} d\xi.
\end{equation}
\end{example}

In finding an optimal Bayesian detector, it is useful to assume that the two probability distributions $\mu_0$ and $\mu_1$ are mutually absolutely continuous.
For example, suppose that the two distributions correspond to probability mass functions or probability density functions with the same support.
Then, an optimal detector can be obtained by looking at the probability of error
\begin{equation*}
\begin{split}
P_e &=  \nu (0) \int_{ \Gamma } \SetIn_{ \Gamma_1 } d\mu_0
+ \nu (1) \int_{ \Gamma } \SetIn_{ \Gamma_0 } d\mu_1 \\
&=  \int_{ \Gamma } \left( \nu (0) \SetIn_{ \Gamma_1 }
+ \nu (1) \SetIn_{ \Gamma_0 } \frac{d\mu_1}{d\mu_0}
\right) d\mu_0 .
\end{split}
\end{equation*}
Since we have the flexibility of choosing the value of $\hat{H}$ for every point $y \in \Gamma$, the optimal detector $\hat{H}^*$ is given by
\begin{equation*}
\hat{H}^* (y) = \arg \min_{\{ 0, 1 \}}
\left( \nu (0) \SetIn_{ \Gamma_1 }(y)
+ \nu (1) \SetIn_{ \Gamma_0 }(y) \frac{d\mu_1}{d\mu_0} (y) \right) .
\end{equation*}
This detector can be expressed in a simpler form as
\begin{equation*}
\frac{d\mu_1}{d\mu_0} (y)
\decreg{H_1}{H_0}
\frac{\nu(0)}{\nu(1)} .
\end{equation*}
The function on the left hand side of the decision rule is called the \emph{likelihood ratio} and it is often denoted by $L(\cdot)$.
In general, a decision test of the form
\begin{equation*}
L(y) \decreg{H_1}{H_0} \eta
\end{equation*}
is called a \emph{likelihood ratio test} (LRT).
A second test that is commonly encountered in the literature is a threshold test on the log-likelihood ratio,
\begin{equation*}
\log ( L (y) )
\decreg{H_1}{H_0} \log \eta .
\end{equation*}
Note that these two decision rules are equivalent, due to the non-decreasing property of the natural logarithm function.

\begin{example}
Suppose that the two hypotheses are equally likely in the digital communication system of Example~\ref{example:BinaryCommunicationSystemII}.
We wish to find the optimal detector.
In this case, the likelihood ratio is equal to
\begin{equation*}
L(y) = \frac
{ \frac{1}{\sqrt{2 \pi}} e^{- \frac{(y-1)^2}{2}} }
{ \frac{1}{\sqrt{2 \pi}} e^{- \frac{y^2}{2}} }
= e^{ \frac{2y-1}{2} } .
\end{equation*}
The optimal detector is therefore given by
\begin{equation*}
e^{ \frac{2y-1}{2} }
\decreg{H_1}{H_0} \frac{ \nu(0) }{ \nu(1) } = 1 .
\end{equation*}
Note that using the log-likelihood version of the test, the optimal decision rule simplifies to
\begin{equation*}
y \decreg{H_1}{H_0} \frac{1}{2} ,
\end{equation*}
as expected.
\end{example}

\begin{example}
Suppose that the probability measure corresponding to the two hypotheses are given by
\begin{align*}
\mu_0 (k) = \frac{ p^k }{k!} e^{-p} \quad k = 0, 1, 2 \ldots \\
\mu_1 (k) = \frac{ q^k }{k!} e^{-q} \quad k = 0, 1, 2 \ldots
\end{align*}
where $0<p<q$.
In this case, note that $\Gamma$ is the set of all positive integers.
We wish to find the format of an optimal test.
The likelihood ratio in this case is given by
\begin{equation*}
L(k) = \left( \frac{q}{p} \right)^k e^{p - q}
\end{equation*}
and the optimal test can be written as
\begin{equation*}
y \decreg{H_1}{H_0} \frac{ \log ( \eta ) + q - p }{ \log q - \log p} .
\end{equation*}
\end{example}


\subsection{Bayesian Risk}

More generally, the Bayesian framework can be defined by assigning cost to each of the four possible outcomes of an experiment.
These outcomes and the corresponding costs can be listed as follows.
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$\hat{H}$ & $H$ & Cost Label & Name\\
\hline
0 & 0 & $C_{00}$ &\\
1 & 0 & $C_{10}$ & False Alarm \\
0 & 1 & $C_{01}$ & Miss \\
1 & 1 & $C_{11}$ & Detection \\
\hline
\end{tabular}
\end{center}
The names of these different scenarios take origin in radar applications, but have since propagated to much of engineering.
In the statistics literature, a false alarm is referred to as a type~I error; whereas a miss is known as a type~II error.
The \emph{Bayesian risk} is the expected value of the cost, and it can be computed using the expression
\begin{equation} \label{equation:BayesianRisk}
\begin{split}
R &= C_{00} \nu (0) \int_{\Gamma} \SetIn_{ \Gamma_0 } d\mu_0
+ C_{10} \nu (0) \int_{\Gamma} \SetIn_{ \Gamma_1 } d\mu_0 \\
&+ C_{01} \nu (1) \int_{\Gamma} \SetIn_{ \Gamma_0 } d\mu_1
+ C_{11} \nu (1) \int_{\Gamma} \SetIn_{ \Gamma_1 } d\mu_1 .
\end{split}
\end{equation}
The \emph{conditional probabilities} defined by the above integrals are very common in the detection literature.
The following notation is also popular,
\begin{align*}
P_F &= \Pr \left( \hat{H} = 1 | H = 0 \right) = \int_{\Gamma_0} d\mu_0 \\
P_D &= \Pr \left( \hat{H} = 1 | H = 1 \right) = \int_{\Gamma_1} d\mu_1 \\
P_M &= \Pr \left( \hat{H} = 0 | H = 1 \right) = \int_{\Gamma_0} d\mu_1 .
\end{align*}
The subscripts are mnemonic for probability of a \emph{false alarm}, \emph{detection}, and \emph{miss}, respectively.

Note that the Bayesian risk of \eqref{equation:BayesianRisk} can be rewritten as
\begin{equation*}
\begin{split}
R = \int_{\Gamma} & \bigg( \nu (0) \left( C_{00} \SetIn_{ \Gamma_0 }
+ C_{10} \SetIn_{ \Gamma_1 } \right) \\
&+ \nu (1) \left( C_{01} \SetIn_{ \Gamma_0 }
+ C_{11} \SetIn_{ \Gamma_1 } \right)
\frac{d\mu_1}{d\mu_0} \bigg) d\mu_0 .
\end{split}
\end{equation*}
Under the assumption that the cost of an erroneous decision is higher than the cost of a correct decision ($C_{10} > C_{00}$ and $C_{01} > C_{11}$), the optimal decision rules is equal to
\begin{equation*}
\frac{d\mu_1}{d\mu_0} (y)
\decreg{H_1}{H_0}
\frac{\nu(0) (C_{10} - C_{00})}{\nu(1) (C_{01} - C_{11})} .
\end{equation*}
Not too surprisingly, the optimal detector is again a likelihood ratio test.
We note that, in this latter case, the decision threshold depends not only on the priors but also on the cost assignment.
Clearly, if we assume that $C_{00} = C_{11} = 0$ and $C_{01} = C_{10} = 1$, the Bayesian risk becomes equivalent to the probability of error.
There may be situations where a different cost assignment is useful.

\newpage
\subsection{Minimax Test}

Using the mnemonic notation introduce above, we can rewrite the Bayesian risk of \eqref{equation:BayesianRisk} as
\begin{equation*}
R = C_{00} \nu(0) (1 - P_F) + C_{10} \nu(0) P_F
+ C_{01} \nu(1) P_M + C_{11} \nu(1) (1 - P_M) .
\end{equation*}
Suppose that a likelihood ratio test is employed with a specific threshold value.
We emphasize that, once $\eta$ is selected, the probability of false alarm and the probability of miss become fixed.
Furthermore, given $\eta$, the Bayesian risk becomes an affine function of $\nu(1)$ because $\nu(0) = 1 - \nu(1)$,
\begin{equation*}
\begin{split}
R &= C_{00} (1 - \nu(1)) (1 - P_F) + C_{10} (1 - \nu(1)) P_F \\
&+ C_{01} \nu(1) P_M + C_{11} \nu(1) (1 - P_M) \\
&= C_{00} (1 - P_F) + C_{10} P_F \\
&+ \left( (C_{01} - C_{11}) P_M + (C_{11} - C_{00})
- (C_{10} - C_{00}) P_F \right) \nu(1) .
\end{split}
\end{equation*}
The value of the risk function above is determined completely by the pair $(\eta, \nu(1))$, where $\eta$ is the threshold of the likelihood ratio test and $\nu(1)$ is the a priori probability of $H_1$.
As such, this function can be represented by $R(\eta, \nu(1))$.
Recall that the class of likelihood ratio tests is optimal in minimizing the Bayesian risk, irrespective of the specific values of the priors.
We can therefore write the optimal risk function as
\begin{equation*}
R^* (\nu(1)) = \inf_{\eta} R(\eta, \nu(1))
\end{equation*}
and since $R^*$ is the infimum of a collection of affine functions, we conclude that $R^*$ is convex in $\nu(1)$.

An interesting problem arises when the value of $\nu(1)$ is not known at the detector.
In this case, one possible approach is to provision for the worst-case.
This approach consists in selecting a decision rule that minimizes the maximum possible risk.
Since likelihood detectors are collectively optimum, this problem can be expressed mathematically as
\begin{equation*}
\min_{\eta} \max_{\nu(1)} R(\eta, \nu(1)) .
\end{equation*}

A cost structure that is frequently used is the special case where $C_{00} = C_{11} = 0$.
In this case,
\begin{equation*}
R = C_{10} P_F + ( C_{01} P_M - C_{10} P_F ) \nu(1) .
\end{equation*}


\section{Neyman-Pearson Hypothesis Testing}

In certain situations, it may be difficult to model parameter $\theta$ as a random variable.
Furthermore, it may be impractical to assign realistic costs to the four detection outcomes.
The Neyman-Pearson framework to binary hypothesis testing provides a possible alternative to the Bayesian formulation.
In this classical approach, $\theta$ is viewed as an unknown deterministic parameter.
The problem is entirely defined in terms of $P_F$ and $P_D$.
The underlying idea is to maximize the probability of detection subject to a constraint on the probability of false alarm.
Mathematically, this goal can be stated as follows
\begin{equation*}
\max P_D \text{ subject to } P_F \leq \alpha .
\end{equation*}

The solution to this constrained optimization problem can be obtained using Lagrange multiplier methods.
For a fixed $\lambda > 0$, we wish to maximize the function
\begin{equation} \label{equation:NeymanPearsonOptimization}
\begin{split}
P_D - \lambda (P_F - \alpha)
&= \int_{\Gamma_1} d\mu_1 - \lambda \int_{\Gamma_1} d\mu_0 + \lambda \alpha \\
&= \int_{\Gamma_1} \left( \frac{d\mu_1}{d\mu_0}  - \lambda \right) d\mu_0
+ \lambda \alpha .
\end{split}
\end{equation}
From the form of \eqref{equation:NeymanPearsonOptimization}, we gather that a likelihood ratio test is again optimal.
the structure of the decision test is then given by
\begin{equation*}
L(y) \decreg{H_1}{H_0} \eta
\end{equation*}
where $\eta$ is the smallest threshold value such that
\begin{equation*}
P_F = \int_{\Gamma_1} d\mu_0 \leq \alpha .
\end{equation*}
and $\Gamma$ is the region given by
\begin{equation*}
\Gamma_1 = \left\{ y \in \Gamma \bigg| \frac{d\mu_1}{d\mu_0}(y) > \eta \right\}
\end{equation*}

\section{Composite Hypothesis Testing}

In the detection problems considered thus far, the subset corresponding to each hypothesis contains exactly one element.
As such, there is a single probability distribution for each hypothesis.
In many problems of interest, each subset of the attribute set may contain more than one element and therefore the observation corresponding to a specific hypothesis may be drawn from a number of probability laws.
The ensuing decision rule becomes more complicated as it must account for the various possibilities.
Such a detection problem where a particular hypothesis encompasses multiple probability laws is known as \emph{composite hypothesis testing}.

Mathematically, the attribute set contains several elements and the set of probability measures is indexed by parameter $\theta$.
Based on the observation $Y$, one must determine if $\theta$ belongs to $H_0$ or $H_1$.
We emphasize that in this scenario, there are multiple probability measures $\mu_{\theta}$ despite the fact that there are only two hypotheses.

In the Bayesian formulation of this composite hypothesis-testing problem, the parameter $\theta$ is assumed to be a random variable and the probability law $\mu_{\theta}$ can be interpreted as the conditional distribution of $Y$ given $\theta$.
The attribute set is partitioned into two subsets and we wish to determined whether $\theta$ belongs to $H_0$ or $H_1$.
Extending the Bayesian framework to this more elaborate case, we define a cost function $C(\hat{H}, \theta)$ where $C(\hat{H}, \theta)$ is the cost of admitting hypothesis $\hat{H}$ given that true parameter $\theta$.
The goal is to find a decision rule $\hat{H} : \Gamma \rightarrow \{ 0, 1 \}$ that minimizes the expected cost
\begin{equation*}
R = \mathrm{E} \left[ C(\hat{H}, \theta) \right]
= \int_{U} \int_{\Gamma} C(\hat{H}, \theta) d\mu_{\theta} d\nu .
\end{equation*}
Using iterated expectations, we can rewrite the Bayes risk as
\begin{equation*}
R = \mathrm{E} \left[ C(\hat{H}, \theta) \right]
= \mathrm{E} \left[ \mathrm{E} \left[ C(\hat{H}, \theta) \Big| Y = y \right] \right] .
\end{equation*}
Note that $R$ is minimized if for each value of $y \in \Gamma$, we choose $\hat{H}(y)$ such that the posterior cost
\begin{equation*}
\mathrm{E} \left[ C(\hat{H}, \theta) \Big| Y = y \right]
= \int_U C(\hat{H}(y), \theta) d\nu
\end{equation*}
is also minimized.
Since the decision $\hat{H}(y)$ can take only two values, 0 or 1, we can see that the optimal detector at point $y \in \Gamma$ is given by
\begin{equation*}
\hat{H}^* (y) = \arg \min_{\ell \in \{ 0, 1 \}}
\mathrm{E} \left[ C(\ell, \theta) \Big| Y = y \right] .
\end{equation*}
This detector can also be expressed in the form
\begin{equation} \label{equation:DecisionRuleCompositeHT}
\mathrm{E} \left[ C(0, \theta) \Big| Y = y \right]
\decreg{H_1}{H_0}
\mathrm{E} \left[ C(1, \theta) \Big| Y = y \right] .
\end{equation}
The optimal detector seeks to minimize the posterior cost.
It selects the hypothesis that leads, on average, to the least cost given observation $y$.

\begin{example}
Consider the scenario where a system attempts to detect the present of a signal embedded in Gaussian noise.
The null hypothesis $H_0$ corresponds to the situation where the signal is absent.
In this case, the probability law on the observation space $\Gamma = \mathbb{R}^2$ is a zero-mean Gaussian random vector with distribution $\mathcal{N}(\mathbf{0}, \sigma^2 I)$.
The signal, if present, has known amplitude but unknown phase;
the phase, which we denote by $\psi$, is uniformly distributed on $[0, 2 \pi)$.
For a specific value of the phase, the induced probability law on $\Gamma$ is
\begin{equation*}
\mu_{(a,\psi)} \sim \mathcal{N} \left( \left[ \begin{array}{c} a \cos \psi \\ a \sin \psi \end{array} \right], \sigma^2 I \right) .
\end{equation*}
The attribute set for this problem can be represented by $U = \{ 0, a \} \times [0, 2 \pi)$.
Let $p(\cdot)$ be the probability mass function of the amplitude, with $p(0) = \Pr (H_0)$ and $p(A) = \Pr (H_1)$.
Then, we can write the joint probability distribution on $U \times \Gamma$ as
\begin{equation*}
\begin{split}
f_{\theta, Y} ( A,\psi, y_1, y_2 )
= \frac{p(A)}{4 \pi^2 \sigma^2}
e^{- \frac{(y_1 - A \cos \psi)^2 + (y_2 - A \sin \psi)^2}{2 \sigma^2} }
\end{split}
\end{equation*}
We can compute the probability distribution on $\Gamma$ as follows
\begin{equation*}
\begin{split}
f_Y ( y_1, y_2 ) &= \sum_{A \in \{ 0, a \}} \int_0^{2 \pi} 
f_{\theta, Y} ( A,\psi, y_1, y_2 ) d\psi \\
&= \frac{ p(0) }{2 \pi \sigma^2}
e^{- \frac{y_1^2 + y_2^2}{2 \sigma^2} }
+ \frac{ p(a) }{4 \pi^2 \sigma^2} \int_0^{2 \pi}
e^{- \frac{(y_1 - a \cos \psi)^2 + (y_2 - a \sin \psi)^2}{2 \sigma^2} }
d\psi \\
&= \frac{1}{2 \pi \sigma^2} e^{- \frac{y_1^2 + y_2^2}{2 \sigma^2} }
\left[ p(0) + p(a) e^{- \frac{a^2}{2 \sigma^2}}
I_0 \left( \frac{a r}{\sigma^2} \right) \right]
\end{split}
\end{equation*}
where $r = \sqrt{ y_1^2 + y_2^2 }$ and $I_0 (\cdot)$ is the zeroth-order modified Bessel function of the first kind defined by
\begin{equation*}
I_0 (x) = \frac{1}{2 \pi} \int_0^{2 \pi} e^{x \cos \phi} d\phi .
\end{equation*}
The conditional probability law on $U$ given observation $Y = (y_1, y_2)$ becomes
\begin{equation*}
f_{\theta | Y} ( A,\psi | y_1, y_2 )
= \frac{f_{\theta, Y} ( A,\psi, y_1, y_2 )}{f_{Y} ( y_1, y_2 )}
= \frac{ p(A) e^{- \frac{A^2}{2 \sigma^2}}
e^{\frac{y_1 A \cos \psi + y_2 A \sin \psi}{ \sigma^2} } }
{ 2 \pi \left[ p(0) + p(a) e^{- \frac{a^2}{2 \sigma^2}}
I_0 \left( \frac{a r}{\sigma^2} \right) \right] } .
\end{equation*}
If the cost function is uniform
\begin{equation*}
C(\ell, A, \psi) = \begin{cases}
0 & \text{if } (\ell,A) = (0,0) \text{ or } (1,a) \\
1 & \text{otherwise}, \end{cases}
\end{equation*}
Computed the conditional risk given $(y_1, y_2)$, the decision rule of \eqref{equation:DecisionRuleCompositeHT} the reduces to
\begin{equation*}
e^{- \frac{a^2}{2 \sigma^2}} I_0 \left( \frac{a r}{\sigma^2} \right)
\decreg{H_1}{H_0} \frac{p(0)}{p(a)} .
\end{equation*}
Note that the function $I_0 (\cdot)$ is monotone increasing, and therefore the optimal test consists in comparing $r$, the magnitude of the received data $(y_1, y_2)$, to a predetermined threshold.
\end{example}
\newpage

\subsection{Classical Framework and Composite Hypotheses}

In general, extending the classical binary detection framwork to composite hypothesis testing is a non-trivial task.
This difficulty stems, partly, from the fact that the decision region corresponding to a Neyman-Pearson test of power $\alpha$ may depend on the actual value of the parameter $\theta$ in each hypothesis subset.
In particular, suppose that $\theta_0 \in H_0$ and $\theta_1 \in H_1$, the decision regions $\Gamma_0$ and $\Gamma_1$ jointly determined by $(\theta_0, \theta_1, \alpha)$ may depend on the actual values of the parameters $\theta_0$ and $\theta_1$.
One possible approach to resolving this issue is to define a \emph{generalized likelihood ratio test} (GLRT); this will be explored later.

\subsubsection{Uniformly Most Powerful Tests}

In some instances, the regions $\Gamma_0$ and $\Gamma_1$ only depend on $\alpha$.
A single decision test is then optimal over all possible values of $\theta_0 \in H_0$ and $\theta_1 \in H_1$.
Such a test is known as a \emph{uniformly most powerful} (UMP) test of level $\alpha$.
This is illustrated in an example below.

\begin{example}
In this example, we explore the detection of a random signal of unknown power embedded in Gaussian noise.
Two cases are possible.
First, when the signal is absent, the observation only contains noise and its distribution is $\mathcal{N}(0,\sigma^2)$.
The signal, if present, is also Gaussian and it is independent of the observation noise.
Given that the signal has power $\sigma_s^2$, the observation distribution becomes $\mathcal{N}(0,\sigma^2 + \theta^2)$.

At first, we assume that the signal power is known and we compute the optimal decision rule for a Neyman-Pearson test with $P_F = \alpha$.
We know that this decision rule is an LRT and, hence, we begin by computing the likelihood ratio.
\begin{equation*}
\frac{ \mu_{\theta} }{ \mu_0 } (y) = \frac{\sigma}{\sqrt{\sigma^2 + \theta^2}} \exp
\left( - \frac{y^2}{2 (\sigma^2 + \theta^2)} + \frac{y^2}{2 \sigma^2} \right)
\end{equation*}
Obviously, the equivalent form of a threshold test on the log-likelihood ratio is more appropriate for this problem.
After simplification, we can write the optimal decision rule as
\begin{equation*}
y^2 \decreg{H_1}{H_0} \tau .
\end{equation*}
Under the condition $P_F = \alpha$, we get an explicit expression for the threshold,
\begin{equation*}
\tau = \left[ \sigma Q^{-1} \left( \frac{\alpha}{2} \right) \right]^2 .
\end{equation*}
Interestingly, we note that the value of the threshold does not depend on $\theta$.
More specifically, the same threshold test is optimal for all signal powers.
This decision rule is a uniformly most powrful test of level $\alpha$.
\end{example}

Although UMP tests are highly desirable, it is important to note that they only exist under special circumstances.

\subsubsection{Locally  Most Powerful Tests}

In many situation, the parameter set corresponding to hyptothesis $H_0$ is a singleton $\{ \theta_0 \}$; and the set associated with $H_1$ contains multiple parameters with a certain order structure, e.g.~$( \theta_0, \infty)$.
We can find a decision region based on a worst-case scenario.
For fixed $\alpha$ and $\theta_1 \in H_1$, we have
\begin{equation*}
P_D (\theta_1) = \int_{\Gamma_1} d \mu_1 .
\end{equation*}
Under suitable regularity considitions, we can expand $P_D (\cdot)$ around $\theta_1 = \theta_0$ through Taylor series and we get
\begin{equation*}
P_D (\theta_1) = P_D (\theta_0) + ( \theta_1 - \theta_0 ) P_D' (\theta_0) + O \left( (\theta_1 - \theta_0)^2 \right) .
\end{equation*}
where $P_D' (\theta) = \partial P_D (\theta) / \partial \theta$.
Note that $\lim_{\theta_1 \downarrow \theta_0} P_D (\theta_1) = P_F = \alpha$.
Thus, we have
\begin{equation*}
P_D (\theta_1) \approx \alpha + ( \theta_1 - \theta_0 ) P_D' (\theta_0)
\end{equation*}
for $\theta_1$ close to $\theta_0$.
Thus, we can achieve approximate optimality for close values of $\theta_1$ by choosing a rule that maximizes $P_D' (\theta_0)$.
Such a test is called a Locally Most Powerful (LMP) test.
\newpage



\section{$M$-ary Hypothesis Testing}

In some instances, the number of possible hypotheses $M$ exceeds two.
This more general scenario can be handled using the Bayesian framework.
Suppose that we are given a cost function $C(\hat{H}, \theta)$ where $\hat{H}$ can take one of $M$ possible values.
That is, the cost function assigns a penalty to each of the alternatives given the true parameter $\theta$.
Again, the objective is to minimize the Bayes risk,
\begin{equation*}
R = \sum_{\ell = 0}^{M-1} \int_U \int_{\Gamma} \SetIn_{\Gamma_{\ell}}
C(\ell, \theta) d\mu_{\theta} d\nu .
\end{equation*}
To find the optimal decision rule, we minimize the risk over all possible partitions $\Gamma_0, \Gamma_1, \ldots, \Gamma_{M-1}$ of the observation space $\Gamma$.
This is a straightforward extension of the binary case,
\begin{equation*}
\begin{split}
\min_{\hat{H}} R
&= \min_{\hat{H}} \sum_{\ell = 0}^{M-1}
\int_U \int_{\Gamma} \SetIn_{\Gamma_{\ell}}
C(\ell, \theta) d\mu_{\theta} d\nu \\
&= \int_{\Gamma} \min_{\ell \in \{0, 1, \ldots, M-1 \} }
E \left[ C(\ell, \theta) \Big| Y = y \right] dy .
\end{split}
\end{equation*}
The optimal detector at point $y \in \Gamma$ is therefore given by
\begin{equation*}
\hat{H}^* (y) = \arg \min_{\ell \in \{ 0, 1, \ldots, M-1 \} }
E \left[ C(\ell, \theta) \Big| Y = y \right] .
\end{equation*}

Consider the case where $U$ contains only $M$ elements, one for each of the possible hypotheses.
Also, assume that the cost is uniform.
In this case, the risk function simplifies to
\begin{equation*}
\begin{split}
R &= \sum_{\ell = 0}^{M-1} \sum_{m \neq \ell} \nu(m)
\int_{\Gamma_{\ell}} d\mu_{m}
= \int_{\Gamma} \sum_{m = 0}^{M-1} \sum_{\ell \neq m} \nu(m)
\SetIn_{\Gamma_{\ell}} d\mu_{m} \\
&= 1 - \int_{\Gamma} \sum_{m = 0}^{M-1} \nu(m)
\SetIn_{\Gamma_{m}} d\mu_{m} .
\end{split}
\end{equation*}
The optimal detector can be rewritten as
\begin{equation*}
\hat{H}^* (y) = \max_{\ell \in \{ 0, 1, \ldots, M-1 \} } \nu(m) d\mu_m (y).
\end{equation*}
That is, the Bayes risk is minimized by selecting the hypothesis with the largest a posteriori probability.

\begin{example}
A quadrature amplitude modulation signal is embedded in additive Gaussian noise.
For specific values of the in-phase and quadrature components, the induced probability law on $\Gamma$ is
\begin{equation*}
\mu_{(i_m, q_m)} \sim \mathcal{N} \left( \left[ \begin{array}{c} i_1 \\ m_2 \end{array} \right], \sigma^2 I \right) .
\end{equation*}
Assuming that all the possible signals are equally likely, we wish to find the decision region for this problem.

We solve this problem by first computing the a posteriori probabilities.
We note that, for equal priors, the optimal decision rule is
\begin{equation*}
\begin{split}
\hat{H}^*(y)
&= \arg \max_{m} \frac{ f_{Y|\theta} ((y_1, y_2) | (i_m, q_m))
\Pr (\theta = (i_m, q_m)) }{ f_{Y} ((y_1, y_2)) } \\
&= \arg \max_{m} f_{Y|\theta} ((y_1, y_2) | (i_m, q_m)) \\
&= \arg \max_{m} \exp \left( - \frac{(y_1 - i_m)^2 + (y_2 - q_m)^2}{2 \sigma^2} \right) \\
&= \arg \min_{m} \sqrt{(y_1 - i_m)^2 + (y_2 - q_m)^2} .
\end{split}
\end{equation*}
Thus, the optimal detector selects an hypothesis by minimizing the Euclidean distance between the received observation and the possible transmitted signals.
\end{example}

How would you prove that \emph{Gray coding} is optimal for minimizing the probability of bit error over a fixed QAM constellation.

%\newpage
%
%\section{Generalized Likelihood Ratio Tests}
%\section{Robust Detection}
%\section{Non-Parametric Detection}
%\section{Decentralized Detection}

\newpage

\section{Detection of Sequential Signals}

So far, we have considered detection problems where the observation is a random variable (or vector).
Our framework can easily be extended to scenarios where the detector has access to a sequence of observations.
In this case, empirical data is obtained sequentially from the realization of a stochastic process.
For the sake of tractability, we consider the case where the observation process is a discrete sequence index by the natural numbers.

We begin our investigation by assuming that observations are conditionally independent and identically distributed, given the true parameter $\theta$.
At a specific time instant $n$, the optimal procedure for deciding between hypotheses $H_0$ and $H_1$ can be derived using our previously derived results about vector observation.
Conditioned on parameter $\theta$, the probability law governing the first $n$ observations is given by
\begin{equation*}
\mu_{\theta}^n = \mu_{\theta} \times \cdots \times \mu_{\theta}
= \prod_{k=1}^n \mu_{\theta} .
\end{equation*}
The optimal decision rule is still a threshold test on the likelihood ratio
\begin{equation*}
\frac{d\mu_1^n}{d\mu_0^n} (y_1, \ldots, y_n)
= \prod_{k=1}^n \frac{d\mu_1}{d\mu_0}(y_k)
\decreg{H_1}{H_0} \eta .
\end{equation*}
We can equivalently write the optimal detection procedure as a threshold test on the normalized likelihood ratio
\begin{equation*}
\frac{1}{n} \log \left( \frac{d\mu_1^n}{d\mu_0^n} (y_1, \ldots, y_n) \right)
= \frac{1}{n} \sum_{k=1}^n \log \left( \frac{d\mu_1}{d\mu_0}(y_k) \right)
\decreg{H_1}{H_0} \frac{ \log \eta }{n} .
\end{equation*}

%\subsection{Sequential Detection}
%\subsection{Quickest Change Detection}

%\newpage

\section{Asymptotic Performance Evaluation}

When the detector obtains a sequence of conditionally independent and identically distributed observations, an optimal decision procedure consists of applying a threshold test on the normalized logarithmic likelihood ratio,
\begin{equation} \label{equation:LogLikelihoodRatio}
\frac{1}{n} \sum_{k=1}^n \log \left( \frac{d\mu_1}{d\mu_0}(y_k) \right) .
\end{equation}
Conditioned on either hypothesis, the logarithmic likelihood ratio of \eqref{equation:LogLikelihoodRatio} is the empirical mean of a sequence of independent and identically distributed random variables.
As such, this test has a form that is suitable for standard concentration results.
In particular, if
\begin{equation*}
E \left[ \left| \log \left( \frac{d\mu_1}{d\mu_0}(y_k) \right) \right| \Big| \theta \right] < \infty ,
\end{equation*}
then the weak law of large numbers applies and \eqref{equation:LogLikelihoodRatio} converges to a constant in probability.
The rate of convergence can be further analyzed using tools form large-deviation theory.
This property forms the basis of our asymptotic performance evaluation.

We begin our exploration of the asymptotic performance of optimal detectors with a simple Gaussian scenario.
This illustrative example servers as a motivation for the material that follows.
This chapter then offers a review of weak laws of large numbers, large deviations, and their applications to hypothesis testing.


\subsection{Gaussian Observations}

In this example, we consider the detection of a signal embedded in Gaussian noise.
The observations are a sequence of conditionally independent and identically distributed random variables.
When the signal is absent, the distribution of each observation is $\mathcal{N}(0,\sigma^2)$.
If the signal is present, the observations are distributed according to $\mathcal{N}(m,\sigma^2)$ where $m > 0$.
The logarithmic likelihood ratio for observation $y_i$ is given by
\begin{equation*}
\log \frac{d\mu_1}{d\mu_0} (y_i) = \frac{y_i m}{\sigma^2} - \frac{m^2}{2 \sigma^2}
\end{equation*}
Combining the observations and assuming equal priors, the optimal decision procedure becomes a threshold test on the normalized logarithmic likelihood ratio,
\begin{equation*}
\frac{1}{n} \sum_{i=1}^n y_i \decreg{H_1}{H_0} \frac{m}{2} .
\end{equation*}

We note that, by the weak law of large numbers,
\begin{equation*}
\frac{1}{n} \sum_{i=1}^n Y_i \rightarrow E[Y_i]
\end{equation*}
in probability as $n \rightarrow \infty$.
In particular, as the number of observations increases, the logarithmic likelihood ratio converges to a constant and the probability of making an erroneous decision approaches zero.
More specifically, we have
\begin{equation*}
P_e^{(n)} = P_F^{(n)} \nu(0) + P_M^{(n)} \nu(1)
= Q \left( \frac{\sqrt{n} m}{2 \sigma} \right) .
\end{equation*}
By the properties of the $Q$-function, we see that $\lim_{n \rightarrow \infty} P_e^{(n)} = 0$.
Note also that
\begin{equation*}
Q(x) \leq  \frac{1}{2} e^{-x^2/2}
\end{equation*}
for $x \geq 0$.
Thus, the rate of convergence of the probability of error is bounded by
\begin{equation*}
\lim_{n \rightarrow \infty} \frac{1}{n} \log P_e^{(n)}
\leq - \frac{m^2}{8 \sigma^2} .
\end{equation*}

We wish to extend this type of asymptotic analysis to more general classes of observations.
This will be accomplished by applying results from large-deviation theory.
We thus pause to review a number of results in applied probability and asymptotic analysis.
These results are applied to detection problems in subsequent sections.


\subsection{Weak Laws of Large Numbers}

The weak law of large numbers can be used to prove that, under proper conditions, the probability of error approaches zero as the number of observations available at the detector grows to infinity.
In words, the law of large numbers asserts that the empirical mean of a sequence of independent and identically distributed random variables conveges in probability to its expected.
Recall that a sequence of random variable $T_1, T_2, \ldots$ converges to $T$ \emph{in probability} if for all $\epsilon > 0$,
\begin{equation*}
\Pr(|T_n - T| > \epsilon) \rightarrow 0
\end{equation*}
as $n \rightarrow \infty$.
We review two different versions of the weak law of large numbers, starting with the simpler one.


\subsubsection{Weak Law in $L^2$}

Suppose that $Z_1, Z_2, \ldots$ are independent random variables with $E Z_i = m$ and $E Z_i^2 = \sigma^2 < \infty$.
It follows that these random variables are \emph{uncorrelated} with
\begin{equation*}
E [ Z_i Z_j ] = (E Z_i) (E Z_j) = m^2 \quad \forall i \neq j .
\end{equation*}
Furthermore, the variance of their sum is the sum of their variances,
\begin{equation*}
\mathrm{Var} \left( \sum_{i=1}^n Z_i \right)
= \sum_{i=1}^n \mathrm{Var} (Z_i)
= n \sigma^2 .
\end{equation*}
This can be seen from the definition of the variance;
\begin{equation*}
\begin{split}
&E \left[ \left( \sum_{i=1}^n Z_i - nm \right)^2 \right]
= E \left[ \left( \sum_{i=1}^n (Z_i - m) \right)^2 \right] \\
&= E \left[\sum_{i=1}^n \sum_{j=1}^n (Z_i - m) (Z_j - m) \right] \\
&= \sum_{i=1}^n E \left[ (Z_i - m)^2 \right]
+ 2 \sum_{i=1}^n \sum_{j=1}^{i-1} E [ (Z_i - m) (Z_j - m) ] ,
\end{split}
\end{equation*}
where in the last equality we have separated the diagonal terms and we have used the fact that the sum over $1 \leq i < j \leq n$ is the same as the sum over $1 \leq j < i \leq n$.
The first term of the last inequality, which we can rewrite as $\sum_{i=1}^n \mathrm{Var} (Z_i)$, is the desired results.
It remains to show that the second term vanishes.
To accomplish this task, we observe that for $i \neq j$ we have
\begin{equation*}
\begin{split}
&E [ (Z_i - m) (Z_j - m) ]
= E [ Z_i Z_j - m Z_j - m Z_i + m^2 ] \\
&= E [ Z_i Z_j ] - m E Z_j - m E Z_i + m^2 \\
&= (E Z_i) (E Z_j) - m^2
= 0 .
\end{split}
\end{equation*}
The last equality holds because $Z_i$ and $Z_j$ are uncorrelated.

As an easy corollary to this result, we obtain the variance of the empirical mean of a sum of independent random variables, each with mean $m$ and variance $\sigma^2$.
Let
\begin{equation*}
S_n = \frac{1}{n} \sum_{i=1}^n Z_i
\end{equation*}
where $Z_1, Z_2, \ldots$ are as defined above, then
\begin{equation*}
\mathrm{Var}(S_n) = \frac{1}{n^2} \mathrm{Var} \left( \sum_{i=1}^n Z_i \right)
= \frac{\sigma^2}{n} .
\end{equation*}
This result is key in establishing the weak law of large numbers in $L^2$.

\begin{theorem}[Weak Law of Large Numbers in $L^2$]
Let $Z_1, Z_2, \ldots$ be a sequence of independent random variables with $E [Z_i] = m$ and $\mathrm{Var}(Z_i) = \sigma^2$.
If
\begin{equation*}
S_n = \frac{1}{n} \sum_{i=1}^n Z_i ,
\end{equation*}
then $S_n \rightarrow m$ in the mean-square sense and in probability as $n \rightarrow \infty$.
\end{theorem}
\begin{proof}
We first prove convergence in $L^2$.
Computing the variance of the empirical mean $S_n$, it follows that
\begin{equation*}
E \left[ ( S_n - m )^2 \right]
= \mathrm{Var} ( S_n )
= \frac{1}{n^2} \sum_{i=1}^n \mathrm{Var} (Z_i)
= \frac{\sigma^2}{n} \rightarrow 0
\end{equation*}
as $n \rightarrow \infty$.
That is, the sequence $S_n$ converges to $m$ in the mean-square sense.
To show convegence in probability, we apply Chebyshev's inequality with $\varphi (s) = s^2$,
\begin{equation*}
\Pr ( | S_n - m | > \epsilon )
\leq \frac{1}{\epsilon^2} E \left[ ( S_n - m )^2 \right]
\rightarrow 0
\end{equation*}
as $n \rightarrow \infty$.
This shows convergence in probability.
\end{proof}

\subsubsection{Weak Law of Large Numbers}

The weak law of large numbers is easiest to prove in $L^2$.
However, this is a strong condition that may not be fulfilled by many random variables of interest.
In this section, we consider an alternate formulation of the theorem.
However, this more general mathematical characterization requires additional work.

The strategy we employ below is to truncate the random summands of $S_n$ and then use the Chebyshev inequality.
We can truncate a random variable $Z$ at a level $n$ as follows,
\begin{equation*}
\bar{Z} = Z \SetIn_{\{ |Z| \leq n \}}
= \begin{cases} Z & \text{if } |Z| \leq n \\
0 & \text{if } |Z| > n . \end {cases}
\end{equation*}

\begin{lemma} \label{lemma:WeakLawTruncated}
Let $Z_1, Z_2, \ldots$ be a sequence of independent and identically distributed random variables.
We define the truncated random variables $\bar{Z}_{i,n}$ by $\bar{Z}_{i,n} = Z_i \SetIn_{\{ |Z_i| \leq n \}}$.
Suppose that $n \Pr (|Z_i| > n) \rightarrow 0$ and
\begin{equation*}
\frac{1}{n} E \bar{Z}_{i,n}^2 \rightarrow 0
\end{equation*}
as $n \rightarrow \infty$.
Then $S_n - m_n$ converges to zero in probability where
\begin{equation*}
S_n = \frac{1}{n} \sum_{i=1}^n Z_i
\quad \text{and} \quad
m_n = \frac{1}{n} \sum_{i=1}^n E \bar{Z}_{i,n}.
\end{equation*}
\end{lemma}
\begin{proof}
Consider the empirical mean $\bar{S}_n$ defined by
\begin{equation*}
\bar{S}_n = \frac{1}{n} \sum_{i=1}^n \bar{Z}_{i,n}
\end{equation*}
We can bound the probability that $S_n$ deviates from its mean as
\begin{equation*}
\Pr (|S_n - m_n| > \epsilon)
\leq \Pr \left( S_n \neq \bar{S}_n \right) + \Pr ( |\bar{S}_n - m_n| > \epsilon) .
\end{equation*}
We examine these two terms individually.
We apply a union bound on the first term and obtain
\begin{equation*}
\begin{split}
&\Pr \left( S_n \neq \bar{S}_n \right)
\leq \Pr \left( \bigcup_{i=1}^n \{ Z_i \neq \bar{Z}_{i,n} \} \right) \\
&\leq \sum_{i=1}^n \Pr (|Z_i| > n) = n \Pr (|Z_i| > n) .
\end{split}
\end{equation*}
To limit the size of the second term, we use the Chebyshev inequality with $\varphi(s) = s^2$,
\begin{equation*}
\begin{split}
&\Pr \left( |\bar{S}_n - m_n| > \epsilon \right)
\leq \frac{1}{\epsilon^2} E \left[ \left( \bar{S}_n - m_n \right)^2 \right] \\
&= \frac{1}{n^2 \epsilon^2} \sum_{i=1}^n \mathrm{Var} \left( \bar{Z}_{i,n} \right)
\leq \frac{1}{n^2 \epsilon^2} \sum_{i=1}^n E \bar{Z}_{i,n}^2
= \frac{1}{n \epsilon^2} E \bar{Z}_{i,n}^2 .
\end{split}
\end{equation*}
In both cases, convergence follows from our assumptions.
\end{proof}

Next, we show that only one of the two conditions assumed in Lemma~\ref{lemma:WeakLawTruncated} is truly needed.

\begin{lemma} \label{lemma:NormalizedTruncatedConvergence}
Let $\bar{Z}_{i,n} = Z_i \SetIn_{\{ |Z_i| \leq n \}}$, as above.
If $n \Pr (|Z_i| > n) \rightarrow 0$ as $n \rightarrow \infty$, then
\begin{equation*}
\frac{1}{n} E \bar{Z}_{i,n}^2
\end{equation*}
also converges to zero as $n \rightarrow \infty$.
\end{lemma}
\begin{proof}
If $X$ is a non-negative random variables with probability law $P$ then
\begin{equation*}
\begin{split}
&\int_0^{\infty} 2 x \Pr (X > x) dx
= \int_0^{\infty} 2 x \int_{\Omega} \SetIn_{\{ X > x \}} dP dx \\
&= \int_{\Omega} \int_0^{\infty} 2 x \SetIn_{\{ X > x \}} dx dP
= \int_{\Omega} \int_0^{X} 2 x dx dP \\
&= \int_{\Omega} X^2 dP = E X^2 .
\end{split}
\end{equation*}
The change in the order of integration can be justified using Fubini's theorem for non-negative random variables.
To prove the desired results, we note that
\begin{equation*}
E \bar{Z}_{i,n}^2
= \int_0^{\infty} 2 x \Pr \left( |\bar{Z}_{i,n}| > x \right) dx
\leq \int_0^n 2 x \Pr ( |Z_i| > x ) dx
\end{equation*}
because $\Pr \left( |\bar{Z}_{i,n}| > x \right) \leq \Pr (|Z_i| > x)$ for all $x \geq 0$.
It remains to show that
\begin{equation*}
\frac{1}{n} \int_0^n 2 x \Pr ( |Z_i| > x ) dx \rightarrow 0
\end{equation*}
as $n \rightarrow \infty$.
The integrant $2 x \Pr(|Z_i| > x)$ is a bounded function since $n \Pr (|Z_i| > n) \rightarrow 0$ as $n \rightarrow \infty$.
In particular, we have $\sup \{ 2 x \Pr(|Z_i| > x) \} < \infty$.
Also, define
\begin{equation*}
\epsilon_m = \sup_{x > m} \{ 2 x \Pr(|Z_i| > x) \} .
\end{equation*}
Then, for any $0 < m < n$, we have
\begin{equation*}
\begin{split}
\int_0^n 2 x \Pr ( |Z_i| > x ) dx
&= \int_0^m 2 x \Pr ( |Z_i| > x ) dx + \int_m^n 2 x \Pr ( |Z_i| > x ) dx \\
&\leq m \sup_{x > 0} \{ 2 x \Pr(|Z_i| > x) \} + (n - m) \epsilon_m .
\end{split}
\end{equation*}
Dividing both sides by $n$ and taking the limit as $n \rightarrow \infty$, we get
\begin{equation*}
\limsup_{n \rightarrow \infty} \frac{1}{n} \int_0^n 2 x \Pr ( |Z_i| > x ) dx
\leq \epsilon_m .
\end{equation*}
Since this is true for any $m$ and given that $\epsilon_m \rightarrow 0$ as $m \rightarrow \infty$, we conclude that the lemma holds.
\end{proof}

We are now ready to prove a more general version of the weak law of large numbers.

\begin{theorem}[Weak Law of Large Numbers]
Let $Z_1, Z_2, \ldots$ be a sequence of independent and identically distributed random variables with $E |Z_i| < \infty$  and $E Z_i = m$.
If
\begin{equation*}
S_n = \frac{1}{n} \sum_{i=1}^n Z_i ,
\end{equation*}
then $S_n \rightarrow m$ in probabilility as $n \rightarrow \infty$.
\end{theorem}
\begin{proof}
By assumption, we have
\begin{equation} \label{equation:ZinL1}
\int_0^{\infty} \Pr (|Z_i| > x) dx = E |Z_i| < \infty .
\end{equation}
Note that $x \SetIn_{\{ |Z_i| > x \}} \leq |Z_i| \SetIn_{\{ |Z_i| > x \}}$ for all $x \in [0, \infty)$.
Integrating both sides of this inequality, we obtain
\begin{equation*}
x \Pr ( |Z_i| > x) \leq E \left[ |Z_i| \SetIn_{\{ |Z_i| > x \}} \right] .
\end{equation*}
By the Lebesgues dominated convergence theorem and \eqref{equation:ZinL1}, we get
\begin{equation*}
x \Pr ( |Z_i| > x) \leq E \left[ |Z_i| \SetIn_{\{ |Z_i| > x \}} \right]
\rightarrow 0
\end{equation*}
as $x \rightarrow \infty$.
From Lemma~\ref{lemma:NormalizedTruncatedConvergence}, we gather that
\begin{equation*}
\frac{1}{n} E \bar{Z}_{i,n}^2 \rightarrow 0
\end{equation*}
as $n \rightarrow 0$.
Together, these two conditions ensure that the sequence $Z_1, Z_2, \ldots$ fulfills the requirements of Lemma~\ref{lemma:WeakLawTruncated}.
Thus, $S_n - m_n$ converges to zero in probability.
To conclude this proof, we need to show that $m_n$ converges to $m$ as $n$ increases.
Observe that $\lim_{n \rightarrow \infty} \bar{Z}_{i,n} = Z_i$.
Since $E |Z_i| < \infty$, we obtain
\begin{equation*}
m_n = E \bar{Z}_{i,n} \rightarrow E Z_i = m
\end{equation*}
as $n \rightarrow \infty$ by Lebesgue's dominated convergence theorem.
\end{proof}


\subsection{Large Deviations}

Cram\'{e}r's theorem characterizes the large deviations associated with the empirical mean of independent and identically distributed random variables.
Suppose that $Z_1, Z_2, \ldots$ is a sequence of independent and identically distributed random variables in $L^1$ with probability law $\upsilon$ and \emph{logarithmic moment generating function}
\begin{equation*}
\Lambda(\lambda) = \log E \left[ e^{\lambda Z_i} \right] ;
\end{equation*}
another common name for $\Lambda (\cdot)$ is the \emph{cumulant generating function}.
Let $\upsilon_n$ denote the probability law of the empirical mean $S_n = \frac{1}{n} \sum_{i=1}^n Z_i$.
By the law of large numbers, we know that $S_n$ converges to $m = E Z_i$ in probability as $n \rightarrow \infty$.
Thus, for any closed set $F$ such that $m \notin F$, $\upsilon_n(F) \rightarrow 0$ as $n \rightarrow \infty$.
Cram\'{e}r's theorem identifies the rate of this convergence in terms of the \emph{Fenchel-Legendre} transform of $\Lambda(\cdot)$, which is given by
\begin{equation*}
\Lambda^*(s) = \sup_{\lambda \in \mathbb{R}} \{ \lambda s - \Lambda(\lambda) \} .
\end{equation*}
We first explore properties of the Fenchel-Legendre transform of $\Lambda (\cdot)$ in a lemma, and then proceed to present Cram\'er's theorem.

\begin{lemma} \label{lemma:PropertiesLambdaStar}
The Fenchel-Legendre transform of $\Lambda(\cdot)$ is a convex function.
Let $\mathcal{D}_{\Lambda} = \{ \lambda : \Lambda (\lambda) < \infty \}$.
The function $\Lambda (\cdot)$ is differentiable in $\mathcal{D}_{\Lambda}^o$ with
\begin{equation} \label{equation:DerivativeLambda}
\Lambda' (\eta) = \frac{1}{M(\eta)} E \left[ Z_i e^{\eta Z_i} \right] ,
\end{equation}
where $M (\lambda) = E e^{\lambda Z_i}$.
\end{lemma}
\begin{proof}
We can show that the logarithmic moment generating function is convex using H\"older's inequality.
For any $\kappa \in [0,1]$, we have
\begin{equation*}
\begin{split}
&\Lambda (\kappa \lambda_1 + (1 - \kappa) \lambda_2)
= \log E \left[ \left( e^{\lambda_1 Z} \right)^{\kappa}
\left( e^{\lambda_2 Z} \right)^{(1 - \kappa)} \right] \\
&\leq \log E \left[ e^{\lambda_1 Z} \right]^{\kappa}
E \left[ e^{\lambda_2 Z} \right]^{(1 - \kappa)}
= \kappa \Lambda(\lambda_1) + (1 - \kappa) \Lambda(\lambda_2) .
\end{split}
\end{equation*}
The convexity of $\Lambda^* (\cdot)$ follows from definition
\begin{equation*}
\begin{split}
&\kappa \Lambda^* (s_1) + (1 - \kappa) \Lambda^* (s_2) \\
&= \sup_{\lambda \in \mathbb{R}} \{ \kappa \lambda s_1 - \kappa \Lambda(\lambda) \}
+ \sup_{\lambda \in \mathbb{R}}
\{ (1 - \kappa) \lambda s_1 - (1 - \kappa) \Lambda(\lambda) \} \\
&\geq \sup_{\lambda \in \mathbb{R}} \{ (\kappa s_1 + (1 - \kappa) s_2) \lambda
- \Lambda(\lambda) \}
= \Lambda^* (\kappa s_1 + (1 - \kappa) s_2) .
\end{split}
\end{equation*}
We note that $\Lambda(0) = 0$ and therefore $\Lambda^*(0) \geq 0$.
When $m = E[Z]$ is finite,
\begin{equation*}
\Lambda(\lambda) = \log E \left[ e^{\lambda Z} \right]
\geq E \left[ \log e^{\lambda Z} \right] = \lambda m
\end{equation*}
by Jensen's inequality.
It follows that
\begin{equation*}
\Lambda^* (m) = \sup_{\lambda \in \mathbb{R}} \{ \lambda m - \Lambda(\lambda) \}
\leq \sup_{\lambda \in \mathbb{R}} \{ \lambda m - \lambda m \} = 0 .
\end{equation*}
Furthermore, for every $s \geq m$ and every $\lambda < 0$,
\begin{equation*}
\lambda s - \Lambda(\lambda)
\leq \lambda m - \Lambda(\lambda)
\leq \lambda m - \lambda m
\leq \Lambda^*(m) = 0 .
\end{equation*}
We can then write
\begin{equation*}
\Lambda^*(s) = \sup_{\lambda \geq 0} \{ \lambda s - \Lambda (\lambda) \}
\end{equation*}
when $s \geq m$.
Using a similar argument, we can show that
\begin{equation*}
\Lambda^*(s) = \sup_{\lambda \leq 0} \{ \lambda s - \Lambda (\lambda) \}
\end{equation*}
when $s \leq m$.

The derivative of \eqref{equation:DerivativeLambda} follows by interchanging the order of differentiation and integration.
This can be justified using Lebesgue's dominated convergence theorem.
First note that $f_{\epsilon}(z) = (e^{(\eta + \epsilon)z} - e^{\eta z})/\epsilon$ converges pointwise to $z e^{\eta z}$ as $\epsilon \rightarrow 0$.
Also, $|f_{\epsilon}(z)| \leq e^{\eta z} (e^{\delta |z|} - 1) / \delta$ for every $\epsilon \in (-\delta, \delta)$.
Furthermore, $E \left[ | e^{\eta z} (e^{\delta |z|} - 1) / \delta | \right] < \infty$ for a small enough $\delta > 0$.
\end{proof}

\begin{theorem}[Cram\'er]
The sequence of meansure $\{ \upsilon_n \}$ corresponding to the empirical means $\{ S_n \}$ satisfies the large deviation principle with convex rate function $\Lambda^* (\cdot )$.
\begin{enumerate}
\item For any closed set $F \subset \mathbb{R}$,
\begin{equation} \label{equation:CramerUpper}
\limsup_{n \rightarrow \infty} \frac{1}{n} \log \upsilon_n (F)
\leq - \inf_{s \in F} \Lambda^* (s) .
\end{equation}
\item For any open set $G \subset \mathbb{R}$,
\begin{equation} \label{equation:CramerLower}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon_n (G)
\geq - \inf_{s \in G} \Lambda^* (s) .
\end{equation}
\end{enumerate}
\end{theorem}
\begin{proof}
We begin this proof by establishing the upper bound of \eqref{equation:CramerUpper}.
If $m \in F$, then $- \inf_{s \in F} \Lambda^*(s) = 0$ and the result is trivial.
Thus, we assume that $m \notin F$.
For every $s > m$, we obtain an upper bound for $\upsilon_n ([s, \infty))$ by applying the Chebycheff inequality.
For $\lambda \geq 0$, we have
\begin{equation*}
\begin{split}
&\upsilon_n ([s, \infty))
= \Pr ( S_n \geq s )
\leq E \left[ e^{n \lambda (S_n - s)} \right] \\
&= e^{-n \lambda s} \prod_{i=1}^n E \left[ e^{\lambda Z_i} \right]
= e^{-n(\lambda s - \Lambda(\lambda))} .
\end{split}
\end{equation*}
Because this inequality holds for any $\lambda \geq 0$, we can take the infimum and obtain
\begin{equation*}
\upsilon_n ([s, \infty)) \leq e^{-n \Lambda^*(s)} .
\end{equation*}
We emphasize that the Fenchel-Legendre of $\Lambda (\cdot)$ appears naturally in the upper bound.
When $s < m$, a similar argument leads to
\begin{equation*}
\upsilon_n ((-\infty,s]) \leq e^{-n \Lambda^*(s)} .
\end{equation*}
We can combine these two upper bounds to establish \eqref{equation:CramerUpper}.
Let $(s_{-}, s_{+})$ be the union of all open intervals in $F^c$ that contain $m$.
This set is non-empty because $F^c$ is open and $m \in F^c$ by construction.
It follows that $F \subset (-\infty, s_{-}] \cup [s_{+}, \infty)$ and
\begin{equation*}
\upsilon_n(F) \leq \upsilon ((-\infty, s_{-}])
+ \upsilon ([s_{+}, \infty))
\leq 2 e^{- n \inf_{s \in F} \Lambda^* (s)} .
\end{equation*}
Equation~\eqref{equation:CramerUpper} follows by taking the logarithm of both sides, dividing by $n$ and taking the limsup as $n \rightarrow \infty$.

To prove the lower bound of \eqref{equation:CramerLower}, we first show that for every $\delta > 0$
\begin{equation} \label{equation:CramerCenteredLower}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon_n ((- \delta, \delta))
\geq \inf_{\lambda \in \mathbb{R}} \Lambda (\lambda) = - \Lambda^*(0) .
\end{equation}
Suppose that $\upsilon ((- \infty, 0)) > 0$, $\upsilon ((0, \infty)) > 0$, and that $\upsilon$ is supported on a bounded subset of $\mathbb{R}$.
This implies that $\Lambda (\lambda) \rightarrow \infty$ as $|\lambda| \rightarrow \infty$, and that $\Lambda (\cdot)$ remains finite everywhere.
Thus, by Lemma~\ref{lemma:PropertiesLambdaStar}, we conclude that $\Lambda (\cdot)$ is a continuous, differentiable function.
In particular, there exists a finite $\zeta$ such that
\begin{equation*}
\Lambda(\zeta) = \inf_{\lambda \in \mathbb{R}} \Lambda (\lambda)
\end{equation*}
and $\Lambda'(\zeta) = 0$.
We define the probability law $\tilde{\upsilon}$ by tilding measure $\upsilon$ as follows,
\begin{equation*}
\frac{d \tilde{\upsilon}}{d \upsilon} (z) = e^{\zeta z - \Lambda(\zeta)} .
\end{equation*}
We emphasize that this new probability law is normalized with
\begin{equation*}
\int_{-\infty}^{\infty} d \tilde{\upsilon}
= e^{- \Lambda(\zeta)} \int_{-\infty}^{\infty} e^{\zeta z} d\upsilon
= \frac{1}{E e^{\zeta z}} E e^{\zeta z} = 1 .
\end{equation*}
Let $\tilde{\upsilon}_n$ be the law governing $S_n$ when $Z_i$ are independent and identically distributed random variables with distribution $\tilde{\upsilon}$.
For every $\epsilon > 0$, we have
\begin{equation*}
\begin{split}
\upsilon_n ((- \epsilon, \epsilon))
&= \int_{\left| \sum_{i=1}^n z_i \right| < n \epsilon}
\upsilon(dz_1) \cdots \upsilon (dz_n) \\
&\geq e^{- n \epsilon | \zeta |} \int_{\left| \sum_{i=1}^n z_i \right| < n \epsilon}
e^{\zeta \sum_{i=1}^n z_i} \upsilon(dz_1) \cdots \upsilon (dz_n) \\
&= e^{- n \epsilon | \zeta |} e^{n \Lambda(\zeta)}
\int_{\left| \sum_{i=1}^n z_i \right| < n \epsilon}
e^{\sum_{i=1}^n (\zeta z_i - \Lambda(\zeta))} \upsilon(dz_1) \cdots \upsilon (dz_n) \\
&= e^{- n \epsilon | \zeta |} e^{n \Lambda(\zeta)}
\tilde{\upsilon}_n ((- \epsilon, \epsilon)) .
\end{split}
\end{equation*}
By Lemma~\ref{lemma:PropertiesLambdaStar} and our choice of $\zeta$, we have
\begin{equation*}
E_{\tilde{\upsilon}} Z_i = \frac{1}{M(\zeta)} \int_{\mathbb{R}} z e^{\zeta z} d\upsilon
= \Lambda'(\zeta) = 0 .
\end{equation*}
Hence, by the law of large numbers, $\lim_{n \rightarrow \infty} \tilde{\upsilon}_n ((- \epsilon, \epsilon)) = 1$.
It then follows that for every $0 < \epsilon < \delta$,
\begin{equation*}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon ((- \delta, \delta))
\geq \liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon ((- \epsilon, \epsilon))
\ge \Lambda (\zeta) - \epsilon | \zeta | .
\end{equation*}
Since this is true for any $\epsilon > 0$, we obtain \eqref{equation:CramerCenteredLower} by letting $\epsilon \rightarrow 0$.
We can get a similar result for the inerval $(z - \delta, z + \delta)$ by using the transformation $X = Z - z$.
This gives $\Lambda_X (\lambda) = \Lambda(\lambda) - \lambda z$ and $\Lambda_X^* (s) = \Lambda^*(s+z)$.
It follows that for every $z \in \mathbb{R}$ and $\delta > 0$,
\begin{equation*}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon_n (( z - \delta, z + \delta))
\geq - \Lambda^* (z) .
\end{equation*}
Given an open set $G$ with $z \in G$, there exists $\delta > 0$ such that $(z - \delta, z + \delta  ) \subset G$.
The large deviations lower bounds of \eqref{equation:CramerLower} thus follows.

Next, we consider the case where $\upsilon$ is of unbounded support, while both $\upsilon((- \infty,0)) > 0$ and $\upsilon ((0, \infty)) > 0$.
Select real number $N$ such that $\upsilon((- M,0)) > 0$ and $\upsilon ((0, M)) > 0$, and let
\begin{equation*}
\Lambda_N (\lambda) = \log \int_{- M}^M e^{\lambda z} d \upsilon .
\end{equation*}
Let $\bar{\upsilon}$ denote the law of $Z_i$ conditioned on $|Z_i| \leq N$, and similarly let $\bar{\upsilon}_n$ be the law of $S_n$ conditioned on $\{ |Z_i| \leq N , i = 1, \ldots, n \}$.
Then, for all $n$ and every $\delta > 0$, we have
\begin{equation*}
\begin{split}
\upsilon_n ((- \delta, \delta))
&= \Pr (|S_n| < \delta)
\geq \Pr (|S_n| < \delta, |Z_1| \leq M, \ldots, |Z_n| \leq M) \\
&= \bar{\upsilon}_n ((- \delta, \delta)) \upsilon([-N, N])^n .
\end{split}
\end{equation*}
Observe that the proof of \eqref{equation:CramerLower} holds for $\bar{\upsilon}_n$.
Also note that the logarithmic moment generating function for $\bar{\upsilon}$ is $\Lambda_N(\lambda) - \log \upsilon ([-N,N])$.
It follows that
\begin{equation*}
\begin{split}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon_n ((- \delta, \delta))
&\geq \log \upsilon([-N,N]) + \liminf_{n \rightarrow \infty}
\frac{1}{n} \log \bar{\upsilon}_n ((- \delta, \delta)) \\
&\geq \inf_{\lambda \in \mathbb{R}} \Lambda_{N} (\lambda) .
\end{split}
\end{equation*}
Since this is true of all $N$, it follows that
\begin{equation*}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \upsilon_n ((- \delta, \delta))
\geq \limsup_{N \rightarrow \infty}
\inf_{\lambda \in \mathbb{R}} \Lambda_{N} (\lambda) .
\end{equation*}
The function $\Lambda_N (\cdot)$ is non-decreasing in $N$, and therefore so is $- I_N = \inf_{\lambda \in \mathbb{R}} \Lambda_N (\lambda)$.
Moreover, $-I_N \leq \Lambda_N(0) \leq \Lambda (0) = 0$, and hence $I^* = \limsup_{N \rightarrow \infty} I_N \geq 0$.
Now, since $-I_N$ is finite for all N large enough, $-I^* > - \infty$.
Therefore the level sets $\{ \lambda : \Lambda_N (\lambda) \leq - I^* \}$ are non-empty, cmpact sets that are nested with respect to $N$.
Hence, there exists at least one point, denoted $\lambda_0$, in their intersection.
By Lesbegue's monotone convergence theorem $\Lambda(\lambda_0) = \lim_{N \rightarrow \infty} \Lambda (\lambda_0) \leq -I^*$.
This shows that \eqref{equation:CramerLower} holds for $\upsilon$ unbounded.

Finally, if either $\upsilon ((-\infty, 0)) = 0$ or $\upsilon ((0, \infty)) = 0$, then $\Lambda(\cdot)$ is a monotone function with $\inf_{\lambda \in \mathbb{R}} \Lambda (\lambda) = \log \upsilon (\{ 0 \})$.
Hence, in this case, \eqref{equation:CramerLower} follows from
\begin{equation*}
\upsilon_n ((-\delta,\delta)) \geq \upsilon_n(\{0\}) = \upsilon (\{0\})^n .
\end{equation*}
\end{proof}

\newpage

\subsection{Asymptotic Tests}

Suppose $Y_1, Y_2, \ldots$ is a sequence of random variables.
We wish to determine whether the sequence of observations is distributed according to $\mu_0^n$ or $\mu_1^n$, correspondng to hypotheses $H_0$ and $H_1$ respectively.
A decision test $\mathcal{S}$ is a sequence of decision functions $\mathcal{S}^n : \Gamma^n \rightarrow \{ 0, 1 \}$, with the interpretation that when $(Y_1, \ldots, Y_n) = (y_1, \ldots, y_n)$ is observed, then $H_0$ is accepted if $\mathcal{S}^n (y_1, \ldots, y_n) = 0$, while $H_1$ is admitted if $\mathcal{S}^n (y_1, \ldots, y_n) = 1$.

The performance of a decision test $\mathcal{S}$ is determined by the conditional probabilities of error
\begin{align*}
\alpha_n &= \Pr (\mathcal{S} = 1 | H_0) &
\beta_n &= \Pr (\mathcal{S} = 0 | H_1) .
\end{align*}
Our first goal is to minimize $\beta_n$, subject to a contraint on $\alpha_n$.
Again, assume that $\mu_0$ and $\mu_1$ are mutually absolutely continuous and that they are distinguishable.
Then, the corresponding likelihood ratio $\frac{d\mu_1}{d\mu_0}$ exists.
We denote the observed logarithmic likelihood ratio by
\begin{equation*}
X_j = \log \frac{d \mu_1}{d \mu_0} (y_j) .
\end{equation*}
Note that we have
\begin{equation*}
E_{\mu_0} X_j = E_{\mu_1} \left[ X_j e^{- X_j} \right]
\end{equation*}
and therefore $E_{\mu_0} X_j$ exists (with possibly $E_{\mu_0} X_j = - \infty$) as $xe^{-x} \leq 1$.
Likewise, we can write
\begin{equation*}
E_{\mu_1} X_j = E_{\mu_0} \left[ X_j e^{X_j} \right] > E_{\mu_0} X_j ,
\end{equation*}
which implies that $E_{\mu_1} X_j$ exists (with possibly $E_{\mu_1} X_j = \infty$) because $X_1$ is non-zero with positive probability.

A Neyman-Pearson test is a decision rule in which, for any $n \in \mathbb{N}$, the normalized observed logarithmic likelihood ratio
\begin{equation*}
S_n = \frac{1}{n} \sum_{j=1}^n X_j
\end{equation*}
is compared to a threshold $\gamma_n$.
Hypothesis $H_1$ is accepted when $S_n$ exceeds $\gamma_n$, whereas $H_0$ is admited whenever $S_n \leq \gamma_n$.
We have already seen that for finite $n$, Neyman-Pearson tests are optimal.
The exponential rates of $\alpha_n$ and $\beta_n$ for Neyman-Pearson test with constant thresholds $\gamma$ are therefore of interest.
These rates can be obtained by looking at the large deviations of $S_n$.

\begin{theorem} \label{theorem:AsymptoticHypothesisTesting}
The Neyman-Pearson test with constant threshold $\gamma \in (E_{\mu_0} X_j, E_{\mu_1} X_j)$ satisfies
\begin{align*}
\lim_{n \rightarrow \infty} \frac{1}{n} \log \alpha_n = - \Lambda_0^* (\gamma) < 0 \\
\lim_{n \rightarrow \infty} \frac{1}{n} \log \beta_n = \gamma - \Lambda_0^* (\gamma) < 0
\end{align*}
where $\Lambda_0^* (\cdot)$ is the Fenchel-Legendre transform of
\begin{equation*}
\Lambda_0 (\lambda) = \log E_{\mu_0} \left[ e^{\lambda X_j} \right] .
\end{equation*}
\end{theorem}

\begin{proof}
Note that $\alpha_n = \Pr (S_n \in (\gamma, \infty) | H_0)$ and $\beta_n = \Pr (S_n \in (-\infty, \gamma] | H_1)$ .
\end{proof}

A corollary of the preceding theorem is Chernoff's asymptotic bound on the best achievable Bayes probability of error,
\begin{equation*}
P_e^{(n)} = \alpha_n \Pr (H_0) + \beta_n \Pr (H_1) .
\end{equation*}

\begin{theorem}[Chernoff]
If $0 < \Pr (H_0) < 1$, then
\begin{equation*}
\inf_{\mathcal{S}} \liminf_{n \rightarrow \infty} \frac{1}{n} \log P_e^{(n)}
= - \Lambda_0^* (0) ,
\end{equation*}
where the infimum is over all decision tests.
\end{theorem}
\begin{proof}
Neyman-Pearson decision rules being optimal for finite $n$, it suffices to consider Neyman-Pearson tests.
Let $\alpha^*$ and $\beta^*$ be the error probabilities for the zero threshold Neyman-Pearson test.
For any other Neyman-Pearson test, either $\alpha_n \geq \alpha_n^*$ or $\beta_n \geq \beta_n^*$.
Thus, for any test
\begin{equation*}
\frac{1}{n} \log P_e^{(n)} \geq \frac{1}{n} \log \min \{ \nu (0), \nu(1) \}
+ \min \left\{ \frac{1}{n} \log \alpha_n^*, \frac{1}{n} \log \beta_n^* \right\} .
\end{equation*}
Hence, as $0 < \nu(0) < 1$,
\begin{equation*}
\inf_{\mathcal{S}} \liminf_{n \rightarrow \infty}
\frac{1}{n} \log P_e^{(n)} \geq \liminf_{n \rightarrow \infty}
\min \left\{ \frac{1}{n} \log \alpha_n^*, \frac{1}{n} \log \beta_n^* \right\} .
\end{equation*}
From the results above, we have
\begin{equation*}
\lim_{n \rightarrow \infty} \frac{1}{n} \log \alpha_n^*
= \lim_{n \rightarrow \infty} \frac{1}{n} \log \beta_n^*
= - \Lambda_0^* (0) .
\end{equation*}
Consequently
\begin{equation*}
\inf_{\mathcal{S}} \liminf_{n \rightarrow \infty}
\frac{1}{n} P_e^{(n)} \geq = - \Lambda_0^* (0) ,
\end{equation*}
with equality for the zero threshold Neyman-Pearson test.
\end{proof}

\begin{theorem}[Stein]
Let $\beta^{\epsilon}_n$ be the infimum of $\beta_n$ among all tests with $\alpha_n < \epsilon$.
For any $\epsilon < 1$,
\begin{equation*}
\lim_{n \rightarrow \infty} \frac{1}{n} \log \beta_n^{\epsilon}
= E_{\mu_0} [ X_j ] = D ( \mu_1 \| \mu_0 ) .
\end{equation*}
\end{theorem}
\begin{proof}
Again, due to the optimality of Neyman-Pearson decision rules, it suffices to consider Neyman-Pearson tests, with
\begin{align*}
\alpha_n &= \Pr (S_n > \gamma_n | H_0) & \beta_n &= \Pr (S_n \leq \gamma_n | H_1) .
\end{align*}
We note that the probability of miss is also given by
\begin{equation*}
\beta_n = \Pr (S_n \leq \gamma_n | H_1)
= E_{\mu_1} \left[ \SetIn_{\{ S_n \leq \gamma_n \}} \right]
= E_{\mu_0} \left[ \SetIn_{\{ S_n \leq \gamma_n \}} e^{n S_n} \right]
\end{equation*}
where the last equality follows by the definition of the log-likelihood ratio $X_j$.
This identity yields the upper bound
\begin{equation*}
\frac{1}{n} \log \beta_n
\leq \frac{1}{n} \log E_{\mu_0} \left[ \SetIn_{\{ S_n \leq \gamma_n \}} e^{n S_n} \right]
\leq \gamma_n
\end{equation*}
Suppose that $E_{\mu_0} [X_j] = - \infty$.
By Theorem~\ref{theorem:AsymptoticHypothesisTesting}, we know that the probability of false alarm eventually becomes less than $\epsilon$ for any admissible $\gamma$.
Therefore, by the preceeding bound, we get
\begin{equation*}
\frac{1}{n} \log \beta_n^{\epsilon} \leq \gamma
\end{equation*}
for all $\gamma$ and $n$ large enough.
This yield the desired result in this case.

Next, supose that $E_{\mu_0} [X_j] > - \infty$.
Without loss of generality, we can assume that
\begin{equation*}
\liminf_{n \rightarrow \infty} \gamma_n \geq E_{\mu_0} [X_j],
\end{equation*}
for otherwise, by the weak law of large numbers, we get
\begin{equation*}
\limsup_{n \rightarrow \infty} \alpha_n = 1 .
\end{equation*}
Consequently, if $\alpha_n < \epsilon$, the weak law of large numbers implies that
\begin{equation*}
\liminf_{n \rightarrow \infty} \Pr (S_n \in [ E_{\mu_0} X_j - \eta, \gamma_n]) \geq 1 - \epsilon, \quad \forall \eta > 0 .
\end{equation*}
Hence, by the identity
\begin{equation*}
\begin{split}
\frac{1}{n} \log \beta_n
&\geq \frac{1}{n} \log E_{\mu_0} \left[ \SetIn_{ S_n \in [\bar{x}_0 - \eta, \gamma_n] }
e^{n S_n} \right] \\
&\geq E_{\mu_0} X_j - \eta + \frac{1}{n} \log \Pr (S_n \in [\bar{x}_0 - \eta, \gamma_n] | H_0) .
\end{split}
\end{equation*}
Combining the above two equations, the optimality of the Neyman-Pearson tests yields
\begin{equation*}
\liminf_{n \rightarrow \infty} \frac{1}{n} \log \beta_n^{\epsilon}
\geq \bar{x}_0 - \eta, \quad \forall \eta > 0 .
\end{equation*}
By Theorem~\ref{theorem:AsymptoticHypothesisTesting}, eventually $\alpha_n < \epsilon$ for any Neyman-Pearson test with a fixed threshold $\gamma > \bar{x}_0$.
Hence
\begin{equation*}
\limsup_{n \rightarrow \infty} \frac{1}{n} \log \beta_n^{\epsilon}
\leq \bar{x}_0 + \eta, \quad \forall \eta > 0, \epsilon > 0 .
\end{equation*}
Since $\eta$ is arbitrary, the conclusion follows.
\end{proof}

