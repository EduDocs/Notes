\chapter{Sum of Independent Random Variables}

\section{Law of Large Numbers}

\begin{theorem}[The Weak Law of Large Numbers]
Let $X_1, X_2, \ldots$ be independent identically distributed random variables with mean $m$.
For every $\epsilon > 0$, we have
\begin{equation*}
\Pr \left( |S_n - m| \geq \epsilon \right)
= \Pr \left( \left| \frac{X_1 + \cdots + X_n}{n} - m \right| \geq \epsilon \right) \rightarrow 0.
\end{equation*}
\end{theorem}
\begin{proof}
\begin{equation*}
S_n = \frac{X_1 + \cdots X_n}{n} .
\end{equation*}
We have
\begin{equation*}
\Expect [S_n] = 
\frac{\Expect [X_1] + \cdots \Expect [X_n]}{n} = m .
\end{equation*}
Using independence, we also have
\begin{equation*}
\Var (S_n) = \frac{ \Var( X_1 + \cdots + X_n )}{n^2}
= \frac{ \Var( X_1 ) + \cdots + \Var(X_n )}{n^2}
= \sigma^2 / n
\end{equation*}
We apply the Chebyshev inequality and obtain
\begin{equation*}
\Pr (|M_n - m| \geq \epsilon) \leq \frac{ \sigma^2}{n \epsilon^2} .
\end{equation*}
for any $\epsilon > 0$.
\end{proof}
