\chapter[Combinatorics]{Combinatorics and Intuitive Probability}

The simplest probabilistic scenario is perhaps one where the set of possible outcomes is finite and these outcomes are all equally likely.
A subset of the set of possible outcomes is called an \emph{event}.
Computing the probability of an event amounts to counting the number of elements comprising this event and then dividing the sum by the total number of admissible outcomes.

\begin{example}
The rolling of a fair die is an experiment with a finite number of equally likely outcomes, namely the different faces labeled one through six.
The probability of observing a specific face is equal to
\begin{equation*}
\frac{1}{\text{Number of faces}} = \frac{1}{6} .
\end{equation*}
Similarly, the probability of an arbitrary event can be computed by counting the number of distinct outcomes included in the event.
For instance, the probability of rolling a prime number is
\begin{equation*}
\Pr ( \{ 2, 3, 5 \} )
= \frac{\text{Number of outcomes in event}}{\text{Total number of outcomes}}
= \frac{3}{6} .
\end{equation*}
\end{example}

While counting outcomes may appear intuitively straightforward, it is in many circumstances a daunting task.
Calculating the number of ways that certain patterns can be formed is part of the field of \emph{combinatorics}. \index{Combinatorics}
In this chapter, we introduce useful counting techniques that can be applied to situations pertinent to probability.


\section{The Counting Principle}

The counting principle is a guiding rule for computing the number of elements in a Cartesian product.
Suppose that $S$ and $T$ are finite sets with $m$ and $n$ elements, respectively.
The Cartesian product of $S$ and $T$ is given by
\begin{equation*}
S \times T = \{ (x, y) | x \in S \text{ and } y \in T \} .
\end{equation*}
The number of elements in the Cartesian product $S \times T$ is equal to $m n$.
This is illustrated in Figure~\ref{figure:CountingPrinciple}.

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\psfrag{2}[c]{$2$}
\psfrag{3}[c]{$3$}
\psfrag{a}[c]{$a$}
\psfrag{b}[c]{$b$}
\includegraphics[height=6.495cm]{Figures/4Chapter/countingprinciple}
\end{psfrags}
\caption{This figure provides a graphical interpretation of the Cartesian product of $S = \{ 1, 2, 3 \}$ and $T = \{ a, b \}$.
In general, if $S$ has $m$ elements and $T$ contains $n$ elements, then the Cartesian product $S \times T$ consists of $m n$ elements.}
\label{figure:CountingPrinciple}
\end{center}
\end{figure}

\begin{example}
Consider an experiment consisting of flipping a coin and rolling a die.
There are two possibilities for the coin, heads or tails, and the die has six faces.
The number of possible outcomes for this experiment is $2 \times 6 = 12$.
That is, there are twelve different ways to flip a coin and roll a die.
\end{example}

Using the equally likely outcome model, the above example implies that the probability of each outcome is $\frac{1}{2} \cdot \frac{1}{6} = \frac{1}{12}$.
This is an instance of the \emph{product rule} for \emph{independent} experiments, which says the probability that two events both occur is given by the product of their individual probabilities if and only if they are independent.
For now, we will interpet the word independent intuitively and take it to mean that the two experiments have no relation to each other.

\begin{example}
Consider two experiments and let $S_1$ be the set of outcomes for the first and $S_2$ be the set of outcomes for the second.
Let $E_1 \subseteq S_1$ and $E_2 \subseteq S_2$ be events of interest for the two experiments.
One can think of the two experiments together as a single experiment with outcomes $S = S_1 \times S_2$.
In this model, the set of joint outcomes where $E_1$ and $E_2$ both occur is given by the joint event $E = E_1 \times E_2$.
The equally likely outcome model for this joint experiment asserts that the probability that both events occur is given by
\[ \frac{|E|}{|S|} = \frac{|E_1 \times E_2|}{|S_1 \times S_2|} = \frac{|E_1|\,|E_2|}{|S_1|\,|S_2|} = \frac{|E_1|}{|S_1|}\,\frac{|E_2|}{|S_2|}. \]
This implies that the product rule is correct when equally-likely experiments are combined this way.
Conversely, events are called independent only if the product rule works.
Therefore, combining multiple experiments in this way amount is the same as assuming they are independent.
\end{example}

The counting principle can be broadened to calculating the number of elements in the Cartesian product of multiple sets.
Consider the finite sets $S_1, S_2, \ldots, S_r$ and their Cartesian product
\begin{equation*}
S_1 \times S_2 \times \cdots \times S_r
= \left\{ (s_1, s_2, \ldots, s_r) | s_i \in S_i \right\} .
\end{equation*}
If we denote the cardinality of $S_i$ by $n_i = | S_i |$, then the number of distinct ordered $r$-tuples of the form $(s_1, s_2, \ldots, s_r)$ is $n = n_1 n_2 \cdots n_r$.

\begin{example}[Sampling with Replacement and Ordering]
An urn contains $n$ balls numbered one through $n$.
A ball is drawn from the urn and its number is recorded on an ordered list.
The ball is then replaced in the urn.
This procedure is repeated $k$ times.
We wish to compute the number of possible sequences that can result from this experiment.
There are $k$ drawings and $n$ possibilities per drawing.
Using the counting principle, we gather that the number of distinct sequences is $n^k$.

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\psfrag{2}[c]{$2$}
\includegraphics[height=1.91cm]{Figures/4Chapter/sequences}
\end{psfrags}
\caption{The Cartesian product $\{ 1, 2 \}^2$ has four distinct ordered pairs.}
\label{figure:Sequences}
\end{center}
\end{figure}
\end{example}

\begin{example}
The \emph{power set} of $S$, denoted by $2^S$, is the collection of all subsets of $S$. \index{Power set}
In set theory, $2^S$ represents the set of all functions from $S$ to $\{ 0, 1\}$.
By identifying a function in $2^S$ with the corresponding preimage of one, we obtain a bijection between $2^S$ and the subsets of $S$.
In particular, each function in $2^S$ is the characteristic function of a subset of $S$.

Suppose that $S$ is finite with $n = |S|$ elements.
For every element of $S$, a characteristic function in $2^S$ is either zero or one.
There are therefore $2^n$ distinct characteristic functions from $S$ to $\{ 0, 1\}$.
Hence, the number of distinct subsets of $S$ is given by $2^n$.

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\psfrag{2}[c]{$2$}
\psfrag{3}[c]{$3$}
\includegraphics[height=4.965cm]{Figures/4Chapter/powerset}
\end{psfrags}
\caption{The power set of $\{ 1, 2, 3 \}$ contains eight subsets.
These elements are displayed above.}
\label{figure:PowerSet}
\end{center}
\end{figure}
\end{example}


\section{Permutations}

Again, consider the integer set $S = \{ 1, 2, \ldots, n \}$.
A \emph{permutation} of $S$ is an ordered arrangement of its elements, i.e., a list without repetitions. \index{Permutation}
The number of permutations of $S$ can be computed as follows.
Clearly, there are $n$ distinct possibilities for the first item in the list.
The number of possibilities for the second item is $n-1$, namely all the integers in $S$ except the element we selected initially.
Similarly, the number of distinct possibilities for the $m$th item is $n - m + 1$.
This pattern continues until all the elements in $S$ are recorded.
Summarizing, we find that the total number of permutations of $S$ is $n$ \emph{factorial}, $n! = n (n-1) \cdots 1$. \index{Factorial}

\begin{example}
We wish to compute the number of permutations of $S = \{ 1, 2, 3 \}$.
Since the set $S$ possesses three elements, it has $3! = 6$ different permutations.
They can be written as $123, 132, 213, 231, 312, 321$.
\end{example}

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\psfrag{2}[c]{$2$}
\psfrag{3}[c]{$3$}
\includegraphics[height=3.06cm]{Figures/4Chapter/permutation}
\end{psfrags}
\caption{Ordering the numbers one, two and three leads to six possible permutations.}
\label{figure:Permutation}
\end{center}
\end{figure}


\subsection{Stirling's Formula*}

The number $n!$ grows very rapidly as a function of $n$.
A good approximation for $n!$ when $n$ is large is given by \emph{Stirling's formula}, \index{Stirling's formula}
\begin{equation*}
n! \sim n^n e^{-n} \sqrt{ 2 \pi n} .
\end{equation*}
The notation $a_n \sim b_n$ signifies that the ratio $a_n / b_n \rightarrow 1$ as $n \rightarrow \infty$.


\subsection{$k$-Permutations}

Suppose that we rank only $k$ elements out of the set $S = \{ 1, 2, \ldots, n \}$, where $k \leq n$.
We wish to count the number of distinct $k$-permutations of $S$.
Following our previous argument, we can choose one of $n$ elements to be the first item listed, one of the remaining $(n-1)$ elements for the second item, and so on.
The procedure terminates when $k$ items have been recorded.
The number of possible sequences is therefore given by
\begin{equation*}
\frac{n!}{(n-k)!} = n (n-1) \cdots (n-k+1) .
\end{equation*}

\begin{example}
A recently formed music group can play four original songs.
They are asked to perform two songs at South by Southwest.
We wish to compute the number of song arrangements the group can offer in concert.
Abstractly, this is equivalent to computing the number of $2$-permutations of four songs.
Thus, the number of distinct arrangements is ${4!}/{2!} = 12$.
\end{example}

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\psfrag{2}[c]{$2$}
\psfrag{3}[c]{$3$}
\psfrag{4}[c]{$4$}
\includegraphics[height=4.215cm]{Figures/4Chapter/kpermutation}
\end{psfrags}
\caption{There are twelve 2-permutations of the numbers one through four.}
\label{figure:Kpermutation}
\end{center}
\end{figure}

\begin{example}[Sampling without Replacement, with  Ordering]
An urn contains $n$ balls numbered one through $n$.
A ball is picked from the urn, and its number is recorded on an ordered list.
The ball is not replaced in the urn.
This procedure is repeated until $k$ balls are selected from the urn, where $k \leq n$.
We wish to compute the number of possible sequences that can result from this experiment.
The number of possibilities is equivalent to the number of $k$-permutations of $n$ elements, which is given by $n! / (n-k)!$.
\end{example}


\section{Combinations}

Consider the integer set $S = \{ 1, 2, \ldots, n \}$.
A \emph{combination} is a subset of $S$. \index{Combination}
We emphasize that a combination differs from a permutation in that elements in a combination have no specific ordering.
The $2$-element subsets of $S = \{ 1, 2, 3, 4 \}$ are
\begin{equation*}
\{ 1, 2 \}, \{ 1, 3 \}, \{ 1, 4 \}, \{ 2, 3 \}, \{ 2, 4 \}, \{ 3, 4 \} ,
\end{equation*}
whereas the $2$-permutations of $S$ are more numerous with
\begin{equation*}
\begin{split}
&( 1, 2 ), ( 1, 3 ), ( 1, 4 ), ( 2, 1 ), ( 2, 3 ), ( 2, 4 ), \\
&( 3, 1 ), ( 3, 2 ), ( 3, 4 ), ( 4, 1 ), ( 4, 2 ), ( 4, 3 ) .
\end{split}
\end{equation*}
Consequently, there are fewer $2$-element subsets of $S$ than $2$-permutations of $S$.

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\psfrag{2}[c]{$2$}
\psfrag{3}[c]{$3$}
\psfrag{4}[c]{$4$}
\includegraphics[height=4.95cm]{Figures/4Chapter/combination}
\end{psfrags}
\caption{There exist six 2-element subsets of the numbers one through four.}
\label{figure:Combination}
\end{center}
\end{figure}

We can compute the number of $k$-element combinations of $S = \{ 1, 2, \ldots, n \}$ as follows.
Note that a $k$-permutation can be formed by first selecting $k$ objects from $S$ and then ordering them.
There are $k!$ distinct ways of ordering $k$ components.
The number of $k$-permutations must therefore be equal to the number of $k$-element combinations multiplied by $k!$.
Since the total number of $k$-permutations of $S$ is $n! / (n-k)!$, we gather that the number of $k$-element combinations is
\begin{equation*}
\binom{n}{k} = \frac{n!}{k! (n-k)!} = \frac{ n (n-1) \cdots (n-k+1) }{ k! } .
\end{equation*}
This expression is termed a \emph{binomial coefficient}. \index{Binomial coefficient}
Observe that selecting a $k$-element subset of $S$ is equivalent to choosing the $n-k$ elements that belong to its complement.
Thus, we can write
\begin{equation*}
\binom{n}{k} = \binom{n}{n-k} .
\end{equation*}

\begin{example}[Sampling without Replacement or Ordering]
An urn contains $n$ balls numbered one through $n$.
A ball is drawn from the urn and placed in a separate jar.
This process is repeated until the jar contains $k$ balls, where $k \leq n$.
We wish to compute the number of distinct combinations the jar can hold after the completion of this experiment.
Because there is no ordering in the jar, this amounts to counting the number of $k$-element subsets of a given $n$-element set, which is given by
\begin{equation*}
\binom{n}{k} = \frac{n!}{k! (n-k)!}.
\end{equation*}
\end{example}

Again, let $S = \{1, 2, \ldots, n\}$.
Since a combination is also a subset and the number of $k$-element combinations of $S$ is $\binom{n}{k}$, the sum of the binomial coefficients $\binom{n}{k}$ over all values of $k$ must be equal to the number of elements in the power set of $S$, \index{Power set}
\begin{equation*}
\sum_{k=0}^n \binom{n}{k} = 2^n .
\end{equation*}


\section{Partitions}

Abstractly, a combination is equivalent to partitioning a set into two disjoint subsets, one containing $k$ objects and the other containing the $n-k$ remaining elements.
In general, the set $S = \{ 1, 2, \ldots, n \}$ can be partitioned into $r$ disjoint subsets.
Let $n_1, n_2, \ldots, n_r$ be nonnegative integers such that
\begin{equation*}
\sum_{i = 1}^r n_i = n.
\end{equation*}
Consider the following iterative algorithm that leads to a \emph{partition} of $S$. \index{Partition}
First, we choose a subset of $n_1$ elements from $S$.
Having selected the first subset, we pick a second subset containing $n_2$ elements from the remaining $n - n_1$ elements.
We continue this procedure by successively choosing subsets of $n_i$ elements from the residual $n - n_1 - \cdots - n_{i-1}$ elements, until no element remains.
This algorithm yields a partition of $S$ into $r$ subsets, with the $i$th subset containing exactly $n_i$ elements.

We wish to count the number of such partitions.
We know that there are $\binom{n}{n_1}$ ways to form the first subset.
Examining our algorithm, we see that there are exactly
\begin{equation*}
\binom{n - n_1 - \cdots - n_{i-1}}{n_i}
\end{equation*}
ways to form the $i$th subset.
Using the counting principle, the total number of partitions is then given by
\begin{equation*}
\binom{n}{n_1} \binom{n - n_1}{n_2}
\cdots \binom{n - n_1 - \cdots - n_{r-1}}{n_r},
\end{equation*}
which after simplification can be written as
\begin{equation*}
\binom{n}{n_1, n_2, \ldots, n_r}
= \frac{n!}{n_1! n_2! \cdots n_r!} .
\end{equation*}
This expression is called a \emph{multinomial coefficient}. \index{Multinomial coefficient}

\begin{example}
A die is rolled nine times.
We wish to compute the number of possible outcomes for which every odd number appears three times.
The number of distinct sequences in which one, three and five each appear three times is equal to the number of partitions of $\{ 1, 2, \ldots, 9 \}$ into three subsets of size three, namely
\begin{equation*}
\frac{9!}{3! 3! 3!} = 1680 .
\end{equation*}
\end{example}


\subsection{Integer Solutions to Linear Equations*}

In the above analysis, we assume that the cardinality of each subset is fixed.
Suppose instead that we are interested in counting the number of ways to pick the cardinality of the subsets that form the partition. \index{Partition}
Specifically, we wish to compute the number of ways integers $n_1, n_2, \ldots, n_r$ can be selected such that every integer is nonnegative and
\begin{equation*}
\sum_{i = 1}^r n_i = n.
\end{equation*}
We can visualize the number of possible assignments as follows.
Picture $n$ balls spaced out on a straight line and consider $r-1$ vertical markers, each of which can be put between two consecutive balls, before the first ball, or after the last ball. 
For instance, if there are five balls and two markers then one possible assignment is illustrated in Figure~\ref{figure:Partitioning}.

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\includegraphics[height=5.28cm]{Figures/4Chapter/partitioning}
\end{psfrags}
\caption{The number of possible cardinality assignments for the partition of a set of $n$ elements into $r$ distinct subsets is equivalent to the number of ways to select $n$ positions out of $n + r - 1$ candidates.} 
\label{figure:Partitioning}
\end{center}
\end{figure}

The number of objects in the first subset corresponds to the number of balls appearing before the first marker.
Similarly, the number of objects in the $i$th subset is equal to the number of balls positioned between the $i$th marker and the preceding one.
Finally, the number of objects in the last subset is simply the number of balls after the last marker.
In this scheme, two consecutive markers imply that the corresponding subset is empty.
For example, the integer assignment associated with the Figure~\ref{figure:Partitioning} is
\begin{equation*}
(n_1, n_2, n_3) = (0,2,3).
\end{equation*}

\begin{figure}[htb!]
\begin{center}
\begin{psfrags}
\psfrag{1}[c]{$1$}
\includegraphics[height=1.53cm]{Figures/4Chapter/partitioning2}
\end{psfrags}
\caption{The assignment displayed in Figure~\ref{figure:Partitioning} corresponds to having no element in the first set, two elements in the second set and three elements in the last one.}
\label{figure:Partitioning2}
\end{center}
\end{figure}

There is a natural relation between an integer assignment and the graphical representation depicted above.
To count the number of possible integer assignments, it suffices to calculate the number of ways to place the markers and the balls.
In particular, there are $n + r - 1$ positions, $n$ balls and $r - 1$ markers.
The number of ways to assign the markers is equal to the number of $n$-combinations of $n + r - 1$ elements,
\begin{equation*}
\binom{n + r - 1}{n} = \binom{n + r - 1}{r - 1} .
\end{equation*}

\begin{example}[Sampling with Replacement, without Ordering]
An urn contains $r$ balls numbered one through $r$.
A ball is drawn from the urn and its number is recorded.
The ball is then returned to the urn.
This procedure is repeated a total of $n$ times.
The outcome of this experiment is a table that contains the number of times each ball has come in sight.
We are interested in computing the number of possible outcomes.
This is equivalent to counting the ways a set with $n$ elements can be partitioned into $r$ subsets.
The number of possible outcomes is therefore given by
\begin{equation*}
\binom{n + r - 1}{n} = \binom{n + r - 1}{r - 1} .
\end{equation*}
\end{example}


\section{Combinatorial Examples}

In this section, we present a few applications of combinatorics to computing the probabilities of specific events.

\begin{example}[Pick 3 Texas Lottery]
The Texas Lottery game ``Pick $3$'' is easy to play.
A player must pick three numbers from zero to nine, and choose how to play them: exact order or any order.
The Pick $3$ balls are drawn using three air-driven machines.
These machines employ compressed air to mix and select each ball.

The probability of winning when playing the exact order is
\begin{equation*}
\frac{1}{10} \frac{1}{10} \frac{1}{10}
= \frac{1}{1000} .
\end{equation*}
The probability of winning while playing any order depends on the numbers selected.
When three distinct numbers are selected, the probability of winning is given by
\begin{equation*}
\frac{3!}{1000} = \frac{3}{500} .
\end{equation*}
If a number is repeated twice, the probability of winning becomes
\begin{equation*}
\frac{\binom{3}{2}}{1000} = \frac{3}{1000} .
\end{equation*}
Finally, if a same number is selected three times, the probability of winning decreases to $1/1000$.
\end{example}

\begin{example}[Mega Millions Texas Lottery]
To play the Mega Millions game, a player must select five numbers from $1$ to $56$ in the upper white play area of the play board, and one Mega Ball number from $1$ to $46$ in the lower yellow play area of the play board.
All drawing equipment is stored in a secured on-site storage room.
Only authorized drawings department personnel have keys to the door.
Upon entry of the secured room to begin the drawing process, a lottery drawing specialist examines the security seal to determine if any unauthorized access has occurred.
For each drawing, the Lotto Texas balls are mixed by four acrylic mixing paddles rotating clockwise.
High speed is used for mixing and low speed for ball selection.
As each ball is selected, it rolls down a chute into an official number display area.
We wish to compute the probability of winning the Mega Millions Grand Prize, which requires the correct selection of the five white balls plus the gold Mega ball.

The probability of winning the Mega Millions Grand Prize is
\begin{equation*}
\frac{1}{\binom{56}{5}} \frac{1}{46}
= \frac{51!5!}{56!} \frac{1}{46}
= \frac{1}{175 711 536} .
\end{equation*}
\end{example}

\begin{example}[Sinking Boat]
Six couples, twelve people total, are out at sea on a sail boat.
Unfortunately, the boat hits an iceberg and starts sinking slowly.
Two Coast Guard vessels, the Ibis and the Mako, come to the rescue.
Each boat can rescue six people.
What is the probability that no two people from a same couple end up on the Mako?

Suppose that rescued passengers are assigned to the Ibis and the Mako  at random.
Then, the number of possible ways to partition these passengers between the two vessels is
\begin{equation*}
\binom{12}{6} = \frac{12!}{6! 6!} .
\end{equation*}
If no two people from a same couple end up on the Mako, then each couple is split between the two vessels.
In these circumstances, there are two possibilities for every couple and, using the counting principle, we gather that there are $2^6$ such assignments.
Collecting these results, we conclude that the probability that no two people from a same couple end up on the Mako is equal to
\begin{equation*}
\frac{2^6}{\binom{12}{6}} = \frac{2^6 6! 6!}{12!} .
\end{equation*}
\end{example}


\section*{Further Reading}

\begin{small}
\begin{enumerate}
\item Ross, S., \emph{A First Course in Probability}, 7th edition, Pearson Prentice Hall, 2006: Chapter~1.
\item Bertsekas, D. P., and Tsitsiklis, J. N., \emph{Introduction to Probability}, Athena Scientific, 2002: Section~1.6.
\item Gubner, J. A., \emph{Probability and Random Processes for Electrical and Computer Engineers}, Cambridge, 2006: Section~1.7.
\end{enumerate}
\end{small}

